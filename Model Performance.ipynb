{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "import copy\n",
    "import random\n",
    "import operator\n",
    "import os, math\n",
    "import re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from stop_words import get_stop_words\n",
    "from collections import Counter, defaultdict\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import torch\n",
    "import torch.utils.data as tud\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 6 labels\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y_labels = ['toxic_y', 'severe_toxic_y', 'obscene_y', 'threat_y', 'insult_y', 'identity_hate_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "def load_data(data_file):\n",
    "    return pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test label set, baseline label set, and proposed label set \n",
    "test_label = load_data(\"test_labels.csv\")\n",
    "baseline = load_data(\"NBSVM_submission.csv\")\n",
    "proposed = load_data(\"model_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the test label that are for testing \n",
    "test_label = test_label[(test_label['toxic'] != -1) & \n",
    "                        (test_label['severe_toxic'] != -1) & \n",
    "                        (test_label['obscene'] != -1) & \n",
    "                        (test_label['threat'] != -1) & \n",
    "                        (test_label['insult'] != -1) &\n",
    "                        (test_label['identity_hate'] != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(data):\n",
    "    \n",
    "    # read in the predicted result, merge with true label \n",
    "    predict = data.merge(test_label, on=['id','id'])\n",
    "    predict = predict.drop(y_labels, axis=1)\n",
    "\n",
    "    true = test_label.drop(\"id\", axis=1)\n",
    "    predict = predict.drop(\"id\", axis=1)\n",
    "\n",
    "    predict.columns = labels\n",
    "\n",
    "    acc = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    # compute accuracy, precision and recall for each column \n",
    "    for i in labels:\n",
    "        y_true = np.array(true[i])\n",
    "        y_predict = np.array(predict[i])\n",
    "\n",
    "        # convert probability to binary, use 0.5 as cut off \n",
    "        y_predict_2 = np.where(y_predict < .5000000000, 0, 1)\n",
    "\n",
    "        acc.append(roc_auc_score(y_true, y_predict))\n",
    "        precision.append(precision_score(y_true, y_predict_2))\n",
    "        recall.append(recall_score(y_true, y_predict_2))\n",
    "\n",
    "    # calculate the average of all columns \n",
    "    acc_scores = sum(acc) / len(acc) \n",
    "    precision_scores = sum(precision) / len(precision) \n",
    "    recall_scores = sum(recall) / len(recall) \n",
    "    return acc_scores, precision_scores, recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_acc_scores, baseline_precision_scores, baseline_recall_scores = output(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accurary: 0.9624293529808764\n",
      "baseline precision: 0.61825263005296\n",
      "baseline recall: 0.4605871765562332\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline accurary: {}\".format(baseline_acc_scores))\n",
    "print(\"baseline precision: {}\".format(baseline_precision_scores))\n",
    "print(\"baseline recall: {}\".format(baseline_recall_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_acc_scores, proposed_precision_scores, proposed_recall_scores = output(proposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proposed accurary: 0.9276368080283678\n",
      "proposed precision: 0.367051421326654\n",
      "proposed recall: 0.6724089318160916\n"
     ]
    }
   ],
   "source": [
    "print(\"proposed accurary: {}\".format(proposed_acc_scores))\n",
    "print(\"proposed precision: {}\".format(proposed_precision_scores))\n",
    "print(\"proposed recall: {}\".format(proposed_recall_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
